# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BZ6jYcsYWqnrs1SziVa_HY1fJ_W-M3Ra
"""

!pip install -q keras

!pip install tensorflow

import numpy as np
import matplotlib.pyplot as plt
import keras
import cv2
from keras.models import Sequential
# from keras.optimizers import Adam
from tensorflow.keras.optimizers import Adam
from keras.layers import Dense
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pickle
import random
import pandas as pd

np.random.seed(0)

!git clone https://bitbucket.org/jadslim/german-traffic-signs

with open('german-traffic-signs/train.p','rb') as f:
    train_data = pickle.load(f)
with open('german-traffic-signs/valid.p','rb') as f:
    val_data = pickle.load(f)  
with open('german-traffic-signs/test.p','rb') as f:
    test_data = pickle.load(f)

X_train, y_train = train_data['features'], train_data['labels']
X_val, y_val = val_data['features'], val_data['labels']
X_test, y_test = test_data['features'], test_data['labels']

print(X_train.shape)
print(X_val.shape)
print(X_test.shape)

assert(X_train.shape[0] == y_train.shape[0]), "The number of images is not equal to the number of labels"
assert(X_val.shape[0] == y_val.shape[0]), "The number of images is not equal to the number of labels"
assert(X_test.shape[0] == y_test.shape[0]), "The number of images is not equal to the number of labels"
assert(X_train.shape[1:] == (32, 32, 3)), "The dimensions of the image is not 32*32*3"
assert(X_val.shape[1:] == (32, 32, 3)), "The dimensions of the image is not 32*32*3"
assert(X_test.shape[1:] == (32, 32, 3)), "The dimensions of the image is not 32*32*3"

data = pd.read_csv('german-traffic-signs/signnames.csv')

num_of_samples = []

cols = 5
num_classes = 43

fig, axs = plt.subplots(nrows = num_classes, ncols = cols, figsize = (5, 50))
fig.tight_layout()

for i in range(cols):
    for j, row in data.iterrows():
        x_selected = X_train[y_train == j]
        axs[j][i].imshow(x_selected[random.randint(0, (len(x_selected)-1)), :, :], cmap = plt.get_cmap("gray"))
        axs[j][i].axis("off")
        if i == 2:
            axs[j][i].set_title(str(j) + "_" + row["SignName"])
            num_of_samples.append(len(x_selected))

print(num_of_samples)
plt.figure(figsize = (12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Training Dataset Distribution")
plt.xlabel("Class number")
plt.ylabel("Number of images")

plt.imshow(X_train[1000])
plt.axis('off')
print(X_train[1000].shape)
print(y_train[1000])

def grayscale(img):
    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    plt.axis('off')
    return image

img = grayscale(X_train[1000])
plt.imshow(img, cmap = 'gray')
print(img.shape)

def equalize(img):
    img = cv2.equalizeHist(img)
    return img

img = equalize(img)
plt.imshow(img, cmap = 'gray')
plt.axis('off')
print(img.shape)

def preprocessing(img):
    img = grayscale(img)
    img = equalize(img)
    img = img/255
    return img

X_train = np.array(list(map(preprocessing, X_train)))
X_val = np.array(list(map(preprocessing, X_val)))
X_test = np.array(list(map(preprocessing, X_test)))

X_train = X_train.reshape(34799, 32, 32, 1)
X_val = X_val.reshape(4410, 32, 32, 1)
X_test = X_test.reshape(12630, 32, 32, 1)

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(width_shift_range = 0.1,
                  height_shift_range = 0.1,
                   zoom_range = 0.2,
                  shear_range = 0.1,
                  rotation_range = 10)

datagen.fit(X_train)

batches = datagen.flow(X_train, y_train, batch_size = 20)
X_batch, y_batch = next(batches)

fig, axs = plt.subplots(1, 15, figsize = (20, 5))
fig.tight_layout()

for i in range(15):
  axs[i].imshow(X_batch[i].reshape(32, 32))
  axs[i].axis('off')

y_train = to_categorical(y_train, 43)
y_val = to_categorical(y_val, 43)
y_test = to_categorical(y_test, 43)

def neural_model():
    model = Sequential()
    model.add(Conv2D(60, (5, 5), input_shape = (32, 32, 1), activation = 'relu'))
    model.add(Conv2D(60, (5, 5), input_shape = (32, 32, 1), activation = 'relu'))
    model.add(MaxPooling2D(pool_size = (2,2)))
    
    model.add(Conv2D(30, (3, 3), activation = 'relu'))
    model.add(Conv2D(30, (3, 3), activation = 'relu'))
    model.add(MaxPooling2D(pool_size = (2, 2)))
    
    #model.add(Dropout(0.5))
    
    model.add(Flatten())
    model.add(Dense(500, activation = 'relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation = 'softmax'))
    model.compile(Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
    return model

model = neural_model()
print(model.summary())

history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 50), steps_per_epoch =int( np.ceil(X_train.shape[0] / 50) ), epochs = 20, validation_data =(X_val, y_val), shuffle = 1)

model.save('signs.h5')

score = model.evaluate(X_test, y_test, verbose = 1)
print('Test Score', score[0])
print('Test Accuracy', score[1])

import requests
from PIL import Image
url = 'https://media.istockphoto.com/id/467751164/photo/wild-animals-crossing-in-austria.jpg?s=612x612&w=0&k=20&c=WjUoo8s21L0zEpHvjuyM_uhdSW9of4HFje-TotmRrzc='
r = requests.get(url, stream=True)
image = Image.open(r.raw)
plt.axis('off')
plt.imshow(image, cmap=plt.get_cmap('gray'))

img = np.asarray(image)
img = cv2.resize(img, (32, 32))
img = preprocessing(img)
plt.imshow(img, cmap = plt.get_cmap('gray'))
print(img.shape)
img = img.reshape(1, 32, 32, 1)

model.predict(img)

predictions=(np.argmax(model.predict(img)))
pred = np.round(predictions).astype(int)
plt.imshow(image)
plt.axis('off')

for num, name in data.iteritems():
  name = name.values
  print("predicted sign: "+ str(name[pred]))

!pip install -q streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import yfinance as yf
# import requests
# import numpy as np
# import matplotlib.pyplot as plt
# import keras
# import cv2
# from keras.models import Sequential
# # from keras.optimizers import Adam
# from tensorflow.keras.optimizers import Adam
# from keras.layers import Dense
# from keras.utils.np_utils import to_categorical
# from keras.layers import Dropout, Flatten
# from keras.layers.convolutional import Conv2D, MaxPooling2D
# import pickle
# import random
# import pandas as pd
# from PIL import Image
# from keras.preprocessing.image import ImageDataGenerator
# import tensorflow as tf
# import plotly.express as px
# from plotly.subplots import make_subplots
# import plotly.graph_objects as go
# from skimage import io
# 
# data = pd.read_csv('german-traffic-signs/signnames.csv')
# 
# def grayscale(img):
#     image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#     plt.axis('off')
#     return image
# 
# def equalize(img):
#     img = cv2.equalizeHist(img)
#     return img
# 
# def preprocessing(img):
#     img = grayscale(img)
#     img = equalize(img)
#     img = img/255
#     return img
# 
# new_model = tf.keras.models.load_model('/content/signs.h5')
# 
# 
# 
# def add_bg_from_url():
#     st.markdown(
#          f"""
#          <style>
#          .stApp {{
#              background-image: url("https://cdn.pixabay.com/photo/2019/04/24/11/27/flowers-4151900_960_720.jpg");
#              background-attachment: fixed;
#              background-size: cover
#          }}
#          </style>
#          """,
#          unsafe_allow_html=True
#      )
# 
# add_bg_from_url() 
# 
# st.title("Sign Detection")
# url = st.text_input("**Enter a traffic sign here** ", "Start typing here")
# if st.button("**Get Result**"):
#     r = requests.get(url, stream=True)
#     image = Image.open(r.raw)
# 
#     img = np.asarray(image)
#     img = cv2.resize(img, (32, 32))
#     img = preprocessing(img)
#     imge = img.reshape(1, 32, 32, 1)
#     new_model.predict(imge)
#     predictions=(np.argmax(new_model.predict(imge)))   
#     pred = np.round(predictions).astype(int)
#     
#   
#     fig = make_subplots(rows=1, cols=2 ,shared_yaxes=False)
#     fig.add_trace(go.Image(z=image), 1, 1)
#     fig.add_trace(go.Heatmap(z=img, colorscale='gray'),1,2).update_yaxes(autorange='reversed',constrain='domain').update_xaxes(constrain='domain')
#   
#     fig
# 
#    
#     for num, name in data.iteritems():
#       name = name.values
#       st.write(f"**predicted sign : {str(name[pred])}**")
#

#https://thumbs.dreamstime.com/b/blue-roundabout-crossroad-road-traffic-sign-against-background-close-105256786.jpg
#https://media.istockphoto.com/id/467751164/photo/wild-animals-crossing-in-austria.jpg?s=612x612&w=0&k=20&c=WjUoo8s21L0zEpHvjuyM_uhdSW9of4HFje-TotmRrzc=
#https://cdn.pixabay.com/photo/2015/08/27/10/45/end-of-speed-limit-910095_1280.png
#https://c8.alamy.com/comp/ARA0HH/keep-left-road-sign-ARA0HH.jpg

#    fig = px.imshow(image)  
 #   st.plotly_chart(fig,caption='Test') 

 #   fig2 = px.imshow(img)  
 #   st.plotly_chart(fig2,labels ={'x':"Gray scaled image"})

!npm install localtunnel

!streamlit run app.py &>/content/logs.txt &

!npx localtunnel --port 8501